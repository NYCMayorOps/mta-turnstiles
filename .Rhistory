entries
) %>%
arrange(id, datetime)
write_csv(dat_mut, filepath)
}
)
df <- map_dfr(
dir_ls(path("data", yr)),
vroom, show_col_types = FALSE, .id = "url"
)
df
walk(
dir_ls(path("data", "pan_baseline")),
function(filepath) {
dat <- vroom(
filepath,
show_col_types = FALSE,
col_types = "cccccccccdd"
)
dat_mut <- set_names(dat, str_to_lower(names(dat))) %>%
rename(c_a = `c/a`) %>%
filter(!(division %in% c("PTH", "RIT"))) %>%
transmute(
id = str_c(c_a, unit, scp, sep = "_"),
datetime = mdy_hms(str_c(date, time, sep = " ")),
station,
linename,
entries
) %>%
arrange(id, datetime)
write_csv(dat_mut, filepath)
}
)
library(tidyverse)
library(lubridate)
library(fs)
library(scales)
library(vroom)
walk(
dir_ls(path("data", "pan_baseline")),
function(filepath) {
dat <- vroom(
filepath,
show_col_types = FALSE,
col_types = "cccccccccdd"
)
dat_mut <- set_names(dat, str_to_lower(names(dat))) %>%
rename(c_a = `c/a`) %>%
filter(!(division %in% c("PTH", "RIT"))) %>%
transmute(
id = str_c(c_a, unit, scp, sep = "_"),
datetime = mdy_hms(str_c(date, time, sep = " ")),
station,
linename,
entries
) %>%
arrange(id, datetime)
write_csv(dat_mut, filepath)
}
)
walk(
dir_ls(path("data", "2022")),
function(filepath) {
dat <- vroom(
filepath,
show_col_types = FALSE,
col_types = "cccccccccdd"
)
dat_mut <- set_names(dat, str_to_lower(names(dat))) %>%
rename(c_a = `c/a`) %>%
filter(!(division %in% c("PTH", "RIT"))) %>%
transmute(
id = str_c(c_a, unit, scp, sep = "_"),
datetime = mdy_hms(str_c(date, time, sep = " ")),
station,
linename,
entries
) %>%
arrange(id, datetime)
write_csv(dat_mut, filepath)
}
)
library(tidyverse)
library(lubridate)
library(fs)
library(scales)
library(vroom)
# data -------------------------------------
## download latest data ------------------------------------------
## updated weekly on saturdays
mta_base_url <- "http://web.mta.info/developers/data/nyct/turnstile/turnstile_"
latest_date <- floor_date(Sys.Date(), "week", 6)
latest_date_fmt <- label_date(format = "%y%m%d")(latest_date)
latest_date_url <- str_c(mta_base_url, latest_date_fmt, ".txt")
read_csv(latest_date_url, show_col_types = FALSE, col_types = "cccccccccdd") %>%
set_names(dat, str_to_lower(names(dat))) %>%
rename(c_a = `c/a`) %>%
filter(!(division %in% c("PTH", "RIT"))) %>%
transmute(
id = str_c(c_a, unit, scp, sep = "_"),
datetime = mdy_hms(str_c(date, time, sep = " ")),
station,
linename,
entries
) %>%
arrange(id, datetime) %>%
write_csv(path("data", "2022", str_c(latest_date_fmt, ".csv")))
## read data ------------------------------------------------------
### station counts ------------------------------------------------
yr <- "2022"
yr_outfile <- str_c(yr, "_station_counts.csv")
df <- map_dfr(
dir_ls(path("data", yr)),
vroom, show_col_types = FALSE, .id = "url"
)
### station info --------------------------------------------------
df_stations <- read_csv(path("data", "stations.csv"))
df_stations_conversion <- read_csv(path("data", "station_conversion.csv"))
## munge daily data -----------------------------------------------
df_daily <- group_by(df, id) %>%
mutate(d_entries = entries - lag(entries),
d_time    = (datetime %--% lag(datetime)) %/% hours()) %>%
ungroup()
df
df_stations_new <- distinct(
df, id,
station,
linename
) %>%
anti_join(df_stations, by = "id") %>%
left_join(df_sta_lat, by = c("station", "linename")) %>%
transmute(id, station = coalesce(station_new, station),
linename = coalesce(linename_new, linename),
lat = Latitude, lon = Longitude)
df_stations_new <- distinct(
df, id,
station,
linename
) %>%
anti_join(df_stations, by = "id") %>%
left_join(df_stations_conversion, by = c("station", "linename")) %>%
transmute(id, station = coalesce(station_new, station),
linename = coalesce(linename_new, linename),
lat = Latitude, lon = Longitude)
df_stations <- bind_rows(df_stations, df_stations_new) %>%
write_csv(path("data", "stations.csv"))
df_ts_easy <- group_by(df_daily, id) %>%
filter(n() >= 5) %>%
ungroup() %>%
# identify most common nonzero sign direction
mutate(sign = sign(d_entries)) %>%
count(id, sign) %>%
filter(sign != 0) %>%
group_by(id) %>%
filter(n == max(n)) %>%
filter(n() == 1) %>%
ungroup()
df_enter_med <- anti_join(df_daily, df_enter_easy, by = "id") %>%
mutate(sign = sign(d_entries)) %>%
group_by(id) %>%
filter(n() >= 5) %>%
summarise(
sign_0 = sum(sign == 0, na.rm = TRUE),
sign_p = sum(sign == 1, na.rm = TRUE),
sign_n = sum(sign == -1, na.rm = TRUE),
med = median(d_entries, na.rm = TRUE),
avg = mean(d_entries, na.rm = TRUE),
min = min(d_entries, na.rm = TRUE),
max = max(d_entries, na.rm = TRUE)
)
df_ts_med <- anti_join(df_daily, df_ts_easy, by = "id") %>%
mutate(sign = sign(d_entries)) %>%
group_by(id) %>%
filter(n() >= 5) %>%
summarise(
sign_0 = sum(sign == 0, na.rm = TRUE),
sign_p = sum(sign == 1, na.rm = TRUE),
sign_n = sum(sign == -1, na.rm = TRUE),
med = median(d_entries, na.rm = TRUE),
avg = mean(d_entries, na.rm = TRUE),
min = min(d_entries, na.rm = TRUE),
max = max(d_entries, na.rm = TRUE)
)
df_sta_weekly_entries <- mutate(
df_ts_daily_entries,
weekdate = floor_date(datetime, unit = "week", week_start = 1),
hr = hour(datetime),
weekday = ifelse(wday(datetime, week_start = 1) %in% 1:5, "weekday", "weekend")
) %>%
filter((weekday == "weekday" & hr %in% c(8:11, 18:21)) |
(weekday == "weekend")) %>%
mutate(
time = map2_chr(
weekday, hr,
~ case_when(
.x == "weekend" ~ "weekend",
.x == "weekday" & .y <= 11 ~ "weekday_am",
.x == "weekady" & .y >  11 ~ "weekday_pm"
)
) %>%
left_join(df_stations, by = "id") %>%
group_by(linename, station, weekdate, time, weekday) %>%
summarise(entries = sum(d_entries),
.groups = "drop") %>%
pivot_wider(names_from = c(weekday, time),
values_from = entries) %>%
write_csv(path("output", yr_outfile), na = "")
df_ts_daily_entries <- left_join(df_ts_easy, df_daily, by = "id") %>%
filter(sign * d_entries >= 0) %>%
arrange(id, datetime) %>%
group_by(id) %>%
mutate(d_entries = (entries - lag(entries)) * sign,
d_time    = (datetime %--% lag(datetime)) %/% hours()) %>%
ungroup() %>%
filter(d_entries < 10000, d_entries >= 0, d_time >= -12)
df_sta_weekly_entries <- mutate(
df_ts_daily_entries,
weekdate = floor_date(datetime, unit = "week", week_start = 1),
hr = hour(datetime),
weekday = ifelse(wday(datetime, week_start = 1) %in% 1:5, "weekday", "weekend")
) %>%
filter((weekday == "weekday" & hr %in% c(8:11, 18:21)) |
(weekday == "weekend")) %>%
mutate(
time = map2_chr(
weekday, hr,
~ case_when(
.x == "weekend" ~ "weekend",
.x == "weekday" & .y <= 11 ~ "weekday_am",
.x == "weekady" & .y >  11 ~ "weekday_pm"
)
) %>%
left_join(df_stations, by = "id") %>%
group_by(linename, station, weekdate, time, weekday) %>%
summarise(entries = sum(d_entries),
.groups = "drop") %>%
pivot_wider(names_from = c(weekday, time),
values_from = entries) %>%
write_csv(path("output", yr_outfile), na = "")
df_sta_weekly_entries <- mutate(
df_ts_daily_entries,
weekdate = floor_date(datetime, unit = "week", week_start = 1),
hr = hour(datetime),
weekday = ifelse(wday(datetime, week_start = 1) %in% 1:5, "weekday", "weekend")
) %>%
filter((weekday == "weekday" & hr %in% c(8:11, 18:21)) |
(weekday == "weekend")) %>%
mutate(
time = map2_chr(
weekday, hr,
~ case_when(
.x == "weekend" ~ "weekend",
.x == "weekday" & .y <= 11 ~ "weekday_am",
.x == "weekady" & .y >  11 ~ "weekday_pm"
)
) %>%
left_join(df_stations, by = "id") %>%
group_by(linename, station, time) %>%
summarise(entries = sum(d_entries),
.groups = "drop") %>%
pivot_wider(names_from = time,
values_from = entries)
df_sta_weekly_entries
df_ts_daily_entries
glimpse(df_ts_daily_entries)
df_ts_daily_entries %>% slice_sample(n = 10)
test1 <- function (data) {
## mutate then filter
mutate(
data,
weekdate = floor_date(datetime, unit = "week", week_start = 1),
hr = hour(datetime),
weekday = ifelse(wday(datetime, week_start = 1) %in% 1:5, "weekday", "weekend"),
time = map2_chr(weekday, hr, ~ case_when(
.x == "weekend" ~ "weekend",
.x == "weekday" & .y <= 11 ~ "weekday_am",
.x == "weekday" & .y >  11 ~ "weekday_pm"
))
) %>%
filter((hr %in% c(8:11, 18:21)) | (weekday == "weekend"))
}
df_ts_daily_entries %>% slice_sample(n = 10) %>% test1
df_ts_daily_entries %>% slice_sample(n = 10) %>% test1 %>% glimpse()
test1 <- function (data) {
## mutate then filter
mutate(
data,
weekdate = floor_date(datetime, unit = "week", week_start = 1),
hr = hour(datetime),
weekday = ifelse(wday(datetime, week_start = 1) %in% 1:5, "weekday", "weekend"),
time = map2_chr(weekday, hr, ~ case_when(
.x == "weekend" ~ "weekend",
.x == "weekday" & .y <= 11 ~ "weekday_am",
.x == "weekday" & .y >  11 ~ "weekday_pm"
))
) %>%
filter(!is.na(time))
}
df_ts_daily_entries %>% slice_sample(n = 10) %>% test1 %>% glimpse()
test1 <- function (data) {
## mutate then filter
mutate(
data,
weekdate = floor_date(datetime, unit = "week", week_start = 1),
time = map_chr(
datetime,
~ case_when(
wday(.) %in% c(1,7) ~ "weekend",
hour(.) <= 11 ~ "weekday_am",
hour(.) >  11 ~ "weekday_pm"
)
) %>%
filter(!is.na(time))
}
test2 <- function(data) {
## filter then mutate
filter(data, hour(datetime) %in% c(8:11, 18:21) | wday(datetime) %in% c(1,7)) %>%
mutate(
weekdate = floor_date(datetime, unit = "week", week_start = 1),
time = map_chr(
datetime,
~ case_when(
wday(.) %in% c(1,7) ~ "weekend",
hour(.) <= 11 ~ "weekday_am",
hour(.) >  11 ~ "weekday_pm"
)
}
install.packages("microbenchmark")
?slice_sample
samp <- slice_sample(df_ts_daily_entries, n = 100)
mb <- microbenchmark::microbenchmark(
mutate_filter = test1(samp),
mutate_filter = test2(samp),
n = 100
)
mb <- microbenchmark::microbenchmark(
mutate_filter = test1(samp),
filter_mutate = test2(samp),
n = 100
)
test1(samp)
test2(samp)
test1 <- function (data) {
## mutate then filter
mutate(
data,
weekdate = floor_date(datetime, unit = "week", week_start = 1),
time = map_chr(
datetime,
~ case_when(
wday(.) %in% c(1,7) ~ "weekend",
hour(.) %in% 8:11 ~ "weekday_am",
hour(.) %in% 18:21 ~ "weekday_pm"
)
) %>%
filter(!is.na(time))
}
test1(samp)
mb <- microbenchmark::microbenchmark(
mutate_filter = test1(samp),
filter_mutate = test2(samp),
n = 100
)
samp <- slice_sample(df_ts_daily_entries, n = 10000)
mb <- microbenchmark::microbenchmark(
mutate_filter = test1(samp),
filter_mutate = test2(samp),
n = 100
)
plot(mb)
mb
?microbenchmark::microbenchmark
samp <- slice_sample(df_ts_daily_entries, n = 1000)
mb <- microbenchmark::microbenchmark(
mutate_filter = test1(samp),
filter_mutate = test2(samp),
times = 100,
unit = "seconds",
check = "equal"
)
autoplot(mb)
mb
tictoc::tic()
df_sta_weekly_entries <- filter(
df_ts_daily_entries,
hour(datetime) %in% c(8:11, 18:21) |
wday(datetime) %in% c(1,7)
) %>%
mutate(
weekdate = floor_date(datetime, unit = "week", week_start = 1),
time = map_chr(
datetime,
~ case_when(
wday(.) %in% c(1,7) ~ "weekend",
hour(.) <= 11 ~ "weekday_am",
hour(.) >  11 ~ "weekday_pm"
)
) %>%
left_join(df_stations, by = "id") %>%
group_by(linename, station, time) %>%
summarise(entries = sum(d_entries),
.groups = "drop") %>%
pivot_wider(names_from = time,
values_from = entries) %>%
write_csv(path("output", yr_outfile), na = "")
tictoc::toc()
df_stations
df_sta_weekly_entries <- filter(
df_ts_daily_entries,
hour(datetime) %in% c(8:11, 18:21) |
wday(datetime) %in% c(1,7)
) %>%
mutate(
weekdate = floor_date(datetime, unit = "week", week_start = 1),
time = map_chr(
datetime,
~ case_when(
wday(.) %in% c(1,7) ~ "weekend",
hour(.) <= 11 ~ "weekday_am",
hour(.) >  11 ~ "weekday_pm"
)
df
df_daily <- select(df, id, datetime, entries) %>%
group_by(id) %>%
mutate(d_entries = entries - lag(entries),
d_time    = (datetime %--% lag(datetime)) %/% hours()) %>%
ungroup()
df_ts_easy <- group_by(df_daily, id) %>%
filter(n() >= 5) %>%
ungroup() %>%
# identify most common nonzero sign direction
mutate(sign = sign(d_entries)) %>%
count(id, sign) %>%
filter(sign != 0) %>%
group_by(id) %>%
filter(n == max(n)) %>%
filter(n() == 1) %>%
ungroup()
df_ts_daily_entries <- left_join(df_ts_easy, df_daily, by = "id") %>%
filter(sign * d_entries >= 0) %>%
arrange(id, datetime) %>%
group_by(id) %>%
mutate(d_entries = (entries - lag(entries)) * sign,
d_time    = (datetime %--% lag(datetime)) %/% hours()) %>%
ungroup() %>%
filter(d_entries < 10000, d_entries >= 0, d_time >= -12)
tictoc::tic()
df_sta_weekly_entries <- filter(
df_ts_daily_entries,
hour(datetime) %in% c(8:11, 18:21) |
wday(datetime) %in% c(1,7)
) %>%
mutate(
weekdate = floor_date(datetime, unit = "week", week_start = 1),
time = map_chr(
datetime,
~ case_when(
wday(.) %in% c(1,7) ~ "weekend",
hour(.) <= 11 ~ "weekday_am",
hour(.) >  11 ~ "weekday_pm"
)
) %>%
left_join(df_stations, by = "id") %>%
group_by(linename, station, time) %>%
summarise(entries = sum(d_entries),
.groups = "drop") %>%
pivot_wider(names_from = time,
values_from = entries) %>%
write_csv(path("output", yr_outfile), na = "")
tictoc::toc()
600/60
df_sta_weekly
df_sta_weekly_entries
tictoc::tic()
df_sta_weekly_entries <- filter(
df_ts_daily_entries,
hour(datetime) %in% c(8:11, 18:21) |
wday(datetime) %in% c(1,7)
) %>%
mutate(
weekdate = floor_date(datetime, unit = "week", week_start = 1),
time = map_chr(
datetime,
~ case_when(
wday(.) %in% c(1,7) ~ "weekend",
hour(.) <= 11 ~ "weekday_am",
hour(.) >  11 ~ "weekday_pm"
)
) %>%
left_join(df_stations, by = "id") %>%
group_by(linename, station, weekdate, time) %>%
summarise(entries = sum(d_entries),
.groups = "drop") %>%
pivot_wider(names_from = time,
values_from = entries) %>%
write_csv(path("output", yr_outfile), na = "")
tictoc::toc()
View(df_sta_weekly_entries)
618/60
renv::restore()
library(tidyverse)
library(lubridate)
library(fs)
library(scales)
library(vroom)
# data -------------------------------------
## download latest data ------------------------------------------
## updated weekly on saturdays
mta_base_url <- "http://web.mta.info/developers/data/nyct/turnstile/turnstile_"
latest_date <- floor_date(Sys.Date(), "week", 6)
latest_date_fmt <- label_date(format = "%y%m%d")(latest_date)
latest_date_url <- str_c(mta_base_url, latest_date_fmt, ".txt")
