tic("all")
mta_base_url <- "http://web.mta.info/developers/data/nyct/turnstile/turnstile_"
latest_date <- floor_date(Sys.Date(), "week", 6)
latest_date_fmt <- label_date(format = "%y%m%d")(latest_date)
latest_date_url <- str_c(mta_base_url, latest_date_fmt, ".txt")
tic("load data")
df_latest <- read_csv(
latest_date_url,
show_col_types = FALSE,
col_types = "cccccccccdd"
) %>%
set_names(str_to_lower(names(.))) %>%
rename(c_a = `c/a`) %>%
filter(!(division %in% c("PTH", "RIT"))) %>%
transmute(
id = str_c(c_a, unit, scp, sep = "_"),
datetime = mdy_hms(str_c(date, time, sep = " ")),
station,
linename,
entries
) %>%
arrange(id, datetime) %>%
write_csv(path("data", "2022", str_c(latest_date_fmt, ".csv")))
## read data ------------------------------------------------------
df_old_ts <- read_csv(path("output", "turnstiles.csv"))
df_old_weekly <- read_csv(path("output", "current_station_counts.csv"))
df_stations <- read_csv(path("data", "stations.csv"))
df_baseline <- read_csv(path("data", "baseline_station_counts.csv"))
toc(log = TRUE, quiet = TRUE)
# daily turnstile counts ---------------------------------------------------
tic("daily turnstile counts")
df_daily_raw <- bind_rows(
select(df_old_ts, id, datetime, entries),
select(df_latest, id, datetime, entries)
) %>%
arrange(id, datetime) %>%
group_by(id) %>%
mutate(d_entries = entries - lag(entries)) %>%
ungroup()
## get turnstile directions -----------------------------------------------
df_ts_dir <- group_by(df_daily_raw, id) %>%
filter(n() >= 5) %>%
ungroup() %>%
# identify most common nonzero sign direction
mutate(sign = sign(d_entries)) %>%
filter(sign != 0) %>%
count(id, sign) %>%
group_by(id) %>%
filter(n == max(n)) %>%
select(-n)
## save turnstile database ------------------------------------------------
tic("turnstile db")
df_ts <- group_by(df_daily_raw, id) %>%
filter(datetime == max(datetime)) %>%
ungroup() %>%
full_join(
select(df_old_ts, id, station, linename),
by = "id"
) %>%
{
if (nrow(.) > nrow(df_old_ts)) {
## TODO: email me if there are new turnstiles??
old_ts <- filter(., !is.na(station))
new_ts <- filter(., is.na(station)) %>%
select(id, datetime, entries) %>%
left_join(distinct(df_latest, id, station, linename), by = "id") %>%
left_join(df_stations, by = c("station", "linename")) %>%
transmute(
id, datetime, entries,
station = coalesce(station_new, station),
linename = coalesce(linename_new, linename)
) %>%
write_csv(path("output", "turnstiles", str_c(latest_date, ".csv")))
bind_rows(old_ts, new_ts)
} else {
select(., -d_entries)
}
} %>%
write_csv(path("output", "turnstiles.csv"))
toc(log = TRUE, quiet = TRUE)
## finish turnstile counts ------------------------------------------------
df_daily <- left_join(
df_daily_raw,
df_ts_dir,
by = "id"
) %>%
filter(sign * d_entries >= 0) %>%
arrange(id, datetime) %>%
group_by(id) %>%
mutate(d_entries = (entries - lag(entries)) * sign,
d_time    = (datetime %--% lag(datetime)) %/% hours()) %>%
ungroup() %>%
filter(d_entries < 10000, d_entries >= 0, d_time >= -12)
toc(log = TRUE, quiet = TRUE)
df_daily
filter(
df_daily,
hour(datetime) %in% c(8:11, 18:21) |
wday(datetime) %in% c(1,7)
) %>%
mutate(
weekdate = floor_date(datetime, unit = "week", week_start = 1),
time = map_chr(
datetime,
~ case_when(
wday(.) %in% c(1,7) ~ "weekend",
hour(.) <= 11 ~ "weekday_am",
hour(.) >  11 ~ "weekday_pm"
)
) %>%
left_join(df_ts, by = "id") %>%
group_by(linename, station, weekdate, time)
df_ts
group_by(df_daily_raw, id) %>%
filter(datetime == max(datetime)) %>%
ungroup() %>%
full_join(
select(df_old_ts, id, station, linename),
by = "id"
)
df_daily_raw
df_old_weekly$weekdate %>% range
df_old_weekly$weekdate %>% unique
latest_date
df_latest$datetime %>% range
df_old_weekly <- read_csv(path("output", "current_station_counts.csv")) %>%
filter(weekdate < min(df_latest$datetime))
df_old_weekly$weekdate %>% unique
df_old_ts
df_old_ts <- read_csv(path("output", "turnstiles", latest_date - weeks(1), ".csv"))
df_old_ts <- read_csv(path("output", "turnstiles", str_c(latest_date - weeks(1), ".csv")))
df_old_ts
group_by(df_daily_raw, id) %>%
filter(datetime == max(datetime)) %>%
ungroup() %>%
full_join(
select(df_old_ts, id, station, linename),
by = "id"
)
## download latest data ------------------------------------------
## updated weekly on saturdays
tic("all")
mta_base_url <- "http://web.mta.info/developers/data/nyct/turnstile/turnstile_"
latest_date <- floor_date(Sys.Date(), "week", 6)
latest_date_fmt <- label_date(format = "%y%m%d")(latest_date)
latest_date_url <- str_c(mta_base_url, latest_date_fmt, ".txt")
tic("load data")
df_latest <- read_csv(
latest_date_url,
show_col_types = FALSE,
col_types = "cccccccccdd"
) %>%
set_names(str_to_lower(names(.))) %>%
rename(c_a = `c/a`) %>%
filter(!(division %in% c("PTH", "RIT"))) %>%
transmute(
id = str_c(c_a, unit, scp, sep = "_"),
datetime = mdy_hms(str_c(date, time, sep = " ")),
station,
linename,
entries
) %>%
arrange(id, datetime) %>%
write_csv(path("data", "2022", str_c(latest_date_fmt, ".csv")))
## read data ------------------------------------------------------
df_old_ts <- read_csv(path("output", "turnstiles", str_c(latest_date - weeks(1), ".csv")))
df_old_weekly <- read_csv(path("output", "current_station_counts.csv")) %>%
filter(weekdate < min(df_latest$datetime))
df_stations <- read_csv(path("data", "stations.csv"))
df_baseline <- read_csv(path("data", "baseline_station_counts.csv"))
toc(log = TRUE, quiet = TRUE)
# daily turnstile counts ---------------------------------------------------
tic("daily turnstile counts")
df_daily_raw <- bind_rows(
select(df_old_ts, id, datetime, entries),
select(df_latest, id, datetime, entries)
) %>%
arrange(id, datetime) %>%
group_by(id) %>%
mutate(d_entries = entries - lag(entries)) %>%
ungroup()
## get turnstile directions -----------------------------------------------
df_ts_dir <- group_by(df_daily_raw, id) %>%
filter(n() >= 5) %>%
ungroup() %>%
# identify most common nonzero sign direction
mutate(sign = sign(d_entries)) %>%
filter(sign != 0) %>%
count(id, sign) %>%
group_by(id) %>%
filter(n == max(n)) %>%
select(-n)
group_by(df_daily_raw, id) %>%
filter(datetime == max(datetime)) %>%
ungroup() %>%
full_join(
select(df_old_ts, id, station, linename),
by = "id"
)
df_old_ts
## full pipeline turnstile analysis
## 2022-05-06
## renata gerecke
# libraries --------------------------------
library(tidyverse)
library(lubridate)
library(fs)
library(scales)
library(vroom)
library(tictoc)
library(httr)
# data -------------------------------------
## download latest data ------------------------------------------
## updated weekly on saturdays
tic("all")
mta_base_url <- "http://web.mta.info/developers/data/nyct/turnstile/turnstile_"
latest_date <- floor_date(Sys.Date(), "week", 6)
latest_date_fmt <- label_date(format = "%y%m%d")(latest_date)
latest_date_url <- str_c(mta_base_url, latest_date_fmt, ".txt")
tic("load data")
df_latest <- read_csv(
latest_date_url,
show_col_types = FALSE,
col_types = "cccccccccdd"
) %>%
set_names(str_to_lower(names(.))) %>%
rename(c_a = `c/a`) %>%
filter(!(division %in% c("PTH", "RIT"))) %>%
transmute(
id = str_c(c_a, unit, scp, sep = "_"),
datetime = mdy_hms(str_c(date, time, sep = " ")),
station,
linename,
entries
) %>%
arrange(id, datetime)
## read data ------------------------------------------------------
df_old_ts <- read_csv(path("output", "turnstiles", str_c(latest_date - weeks(1), ".csv")),
show_col_types = FALSE)
df_old_weekly <- read_csv(path("output", "current_station_counts.csv"),
show_col_types = FALSE) %>%
filter(weekdate < min(df_latest$datetime))
df_stations <- read_csv(path("data", "stations.csv"),
show_col_types = FALSE)
df_baseline <- read_csv(path("data", "baseline_station_counts.csv"),
show_col_types = FALSE)
toc(log = TRUE, quiet = TRUE)
# daily turnstile counts ---------------------------------------------------
tic("daily turnstile counts")
df_daily_raw <- bind_rows(
select(df_old_ts, id, datetime, entries),
select(df_latest, id, datetime, entries)
) %>%
arrange(id, datetime) %>%
group_by(id) %>%
mutate(d_entries = entries - lag(entries)) %>%
ungroup()
## get turnstile directions -----------------------------------------------
df_ts_dir <- group_by(df_daily_raw, id) %>%
filter(n() >= 5) %>%
ungroup() %>%
# identify most common nonzero sign direction
mutate(sign = sign(d_entries)) %>%
filter(sign != 0) %>%
count(id, sign) %>%
group_by(id) %>%
filter(n == max(n)) %>%
select(-n)
## save turnstile database ------------------------------------------------
tic("turnstile db")
df_ts <- group_by(df_daily_raw, id) %>%
filter(datetime == max(datetime)) %>%
ungroup() %>%
full_join(
select(df_old_ts, id, station, linename),
by = "id"
) %>%
{
if (nrow(.) > nrow(df_old_ts)) {
## TODO: email me if there are new turnstiles??
old_ts <- filter(., !is.na(station))
new_ts <- filter(., is.na(station)) %>%
select(id, datetime, entries) %>%
left_join(distinct(df_latest, id, station, linename), by = "id") %>%
left_join(df_stations, by = c("station", "linename")) %>%
transmute(
id, datetime, entries,
station = coalesce(station_new, station),
linename = coalesce(linename_new, linename)
) %>%
write_csv(path("output", "new-turnstiles", str_c(latest_date, ".csv")))
bind_rows(old_ts, new_ts)
} else {
select(., -d_entries)
}
} %>%
write_csv(path("output", "turnstiles", str_c(latest_date, ".csv")))
toc(log = TRUE, quiet = TRUE)
## finish turnstile counts ------------------------------------------------
df_daily <- left_join(
df_daily_raw,
df_ts_dir,
by = "id"
) %>%
filter(sign * d_entries >= 0) %>%
arrange(id, datetime) %>%
group_by(id) %>%
mutate(d_entries = (entries - lag(entries)) * sign,
d_time    = (datetime %--% lag(datetime)) %/% hours()) %>%
ungroup() %>%
filter(d_entries < 10000, d_entries >= 0, d_time >= -12)
toc(log = TRUE, quiet = TRUE)
# weekly station counts ---------------------------------------------------
tic("latest weekly")
df_new_weekly <- filter(
df_daily,
hour(datetime) %in% c(8:11, 18:21) |
wday(datetime) %in% c(1,7)
) %>%
mutate(
weekdate = floor_date(datetime, unit = "week", week_start = 1),
time = map_chr(
datetime,
~ case_when(
wday(.) %in% c(1,7) ~ "weekend",
hour(.) <= 11 ~ "weekday_am",
hour(.) >  11 ~ "weekday_pm"
)
) %>%
left_join(df_ts, by = "id") %>%
group_by(linename, station, weekdate, time) %>%
summarise(entries = sum(d_entries),
.groups = "drop") %>%
pivot_wider(
names_from = time,
values_from = entries
) %>%
mutate(week = week(weekdate))
toc(log = TRUE, quiet = TRUE)
tic("combined weekly")
df_all_weekly <- full_join(
df_new_weekly,
df_old_weekly,
by = c("linename", "station", "weekdate", "week"),
suffix = c(".new", ".old")
) %>%
transmute(
linename,
station,
weekdate,
week,
weekend = coalesce(weekend.new, weekend.old),
weekday_am = coalesce(weekday_am.new, weekday_am.old),
weekday_pm = coalesce(weekday_pm.new, weekday_pm.old)
) %>%
write_csv(path("output", "current_station_counts.csv"), na = "")
toc(log = TRUE, quiet = TRUE)
# compare weekly to baseline ------------------------------------------
df_delta <- left_join(df_all_weekly, df_baseline,
by = c("linename", "station", "week"),
suffix = c("_2022", "_bl")) %>%
mutate(
d_weekend = (weekend_2022) / weekend_bl,
d_weekday_am = (weekday_am_2022) / weekday_am_bl,
d_weekday_pm = (weekday_pm_2022) / weekday_pm_bl
) %>%
na_if(Inf) %>%
left_join(df_stations, by = c("linename", "station")) %>%
write_csv(path("output", "baseline_2022_station_delta.csv"), na = "")
carto_user <- Sys.getenv("CARTO_USER")
carto_key <- Sys.getenv("CARTO_KEY")
carto_url <- str_glue("https://{carto_user}.carto.com/api/v1/imports/?api_key={carto_key}&collision_strategy=overwrite&table_name=mta_turnstiles")
POST(
carto_url,
body = list(
file = upload_file(path("output", "baseline_2022_station_delta.csv"))
)
head(df_delta)
janitor::tabyl(df_delta, station, station_new)
janitor::tabyl(df_delta, station, station_new) %>% View
count(df_delta, station, station_new) %>% View
count(df_delta, station, station_new) %>% filter(station != station_new)
df_stations
df_delta
df_delta <- left_join(df_all_weekly, df_baseline,
by = c("linename", "station", "week"),
suffix = c("_2022", "_bl")) %>%
mutate(
d_weekend = (weekend_2022) / weekend_bl,
d_weekday_am = (weekday_am_2022) / weekday_am_bl,
d_weekday_pm = (weekday_pm_2022) / weekday_pm_bl
) %>%
na_if(Inf) %>%
left_join(df_stations, by = c("linename", "station")) %>%
mutate(linename = linename_new, station = station_new) %>%
select(-ends_with("_new")) %>%
write_csv(path("output", "baseline_2022_station_delta.csv"), na = "")
POST(
carto_url,
body = list(
file = upload_file(path("output", "baseline_2022_station_delta.csv"))
)
df_delta <- left_join(df_all_weekly, df_baseline,
by = c("linename", "station", "week"),
suffix = c("_2022", "_bl")) %>%
mutate(
d_weekend = (weekend_2022) / weekend_bl,
d_weekday_am = (weekday_am_2022) / weekday_am_bl,
d_weekday_pm = (weekday_pm_2022) / weekday_pm_bl
) %>%
na_if(Inf) %>%
left_join(df_stations, by = c("linename", "station")) %>%
mutate(linename = linename_new, station = station_new) %>%
select(-ends_with("_new")) %>%
slice_sample(n = 1000) %>%
write_csv(path("output", "baseline_2022_station_delta.csv"), na = "")
POST(
carto_url,
body = list(
file = upload_file(path("output", "baseline_2022_station_delta.csv"))
)
carto_url <- str_glue("https://{carto_user}.carto.com/api/v1/imports/?api_key={carto_key}&collision_strategy=overwrite")
POST(
carto_url,
body = list(
file = upload_file(path("output", "baseline_2022_station_delta.csv"))
)
POST(
carto_url,
body = list(
file = upload_file(path("output", "baseline_2022_station_delta.csv"))
)
df_delta <- left_join(df_all_weekly, df_baseline,
by = c("linename", "station", "week"),
suffix = c("_2022", "_bl")) %>%
mutate(
d_weekend = (weekend_2022) / weekend_bl,
d_weekday_am = (weekday_am_2022) / weekday_am_bl,
d_weekday_pm = (weekday_pm_2022) / weekday_pm_bl
) %>%
na_if(Inf) %>%
left_join(df_stations, by = c("linename", "station")) %>%
mutate(linename = linename_new, station = station_new) %>%
select(-ends_with("_new")) %>%
slice_sample(n = 2000) %>%
write_csv(path("output", "baseline_2022_station_delta.csv"), na = "")
POST(
carto_url,
body = list(
file = upload_file(path("output", "baseline_2022_station_delta.csv"))
)
df_delta <- left_join(df_all_weekly, df_baseline,
by = c("linename", "station", "week"),
suffix = c("_2022", "_bl")) %>%
mutate(
d_weekend = (weekend_2022) / weekend_bl,
d_weekday_am = (weekday_am_2022) / weekday_am_bl,
d_weekday_pm = (weekday_pm_2022) / weekday_pm_bl
) %>%
na_if(Inf) %>%
left_join(df_stations, by = c("linename", "station")) %>%
mutate(linename = linename_new, station = station_new) %>%
select(-ends_with("_new")) %>%
slice_sample(n = 1000) %>%
write_csv(path("output", "baseline_2022_station_delta.csv"), na = "")
POST(
carto_url,
body = list(
file = upload_file(path("output", "baseline_2022_station_delta.csv"))
)
df_delta <- left_join(df_all_weekly, df_baseline,
by = c("linename", "station", "week"),
suffix = c("_2022", "_bl")) %>%
mutate(
d_weekend = (weekend_2022) / weekend_bl,
d_weekday_am = (weekday_am_2022) / weekday_am_bl,
d_weekday_pm = (weekday_pm_2022) / weekday_pm_bl
) %>%
na_if(Inf) %>%
left_join(df_stations, by = c("linename", "station")) %>%
mutate(linename = linename_new, station = station_new) %>%
select(-ends_with("_new")) %>%
write_csv(path("output", "baseline_2022_station_delta.csv"), na = "")
POST(
carto_url,
body = list(
file = upload_file(path("output", "baseline_2022_station_delta.csv"))
)
df_delta <- left_join(df_all_weekly, df_baseline,
by = c("linename", "station", "week"),
suffix = c("_2022", "_bl")) %>%
mutate(
d_weekend = (weekend_2022) / weekend_bl,
d_weekday_am = (weekday_am_2022) / weekday_am_bl,
d_weekday_pm = (weekday_pm_2022) / weekday_pm_bl
) %>%
na_if(Inf) %>%
left_join(df_stations, by = c("linename", "station")) %>%
mutate(linename = linename_new, station = station_new) %>%
select(-ends_with("_new")) %>%
write_csv(path("output", "baseline_2022_station_delta.csv"), na = "")
file.edit("~/.Renviron")
carto_key <- Sys.getenv("CARTO_KEY")
carto_url <- str_glue("https://{carto_user}.carto.com/api/v1/imports/?api_key={carto_key}&collision_strategy=overwrite")
POST(
carto_url,
body = list(
file = upload_file(path("output", "baseline_2022_station_delta.csv"))
)
renv::clean(actions = "unused.packages")
renv::snapshot()
install.packages("taskscheduleR")
