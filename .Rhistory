weekday_pm = coalesce(weekday_pm.new, weekday_pm.old)
) %>%
write_csv(path("output", str_c("test", "2022_station_counts.csv")), na = "")
tictoc::toc()
## full pipeline turnstile analysis
## 2022-05-06
## renata gerecke
# libraries --------------------------------
library(tidyverse)
library(lubridate)
library(fs)
library(scales)
library(vroom)
# data -------------------------------------
## download latest data ------------------------------------------
## updated weekly on saturdays
mta_base_url <- "http://web.mta.info/developers/data/nyct/turnstile/turnstile_"
latest_date <- floor_date(Sys.Date(), "week", 6)
latest_date_fmt <- label_date(format = "%y%m%d")(latest_date)
latest_date_url <- str_c(mta_base_url, latest_date_fmt, ".txt")
df_latest <- read_csv(
latest_date_url,
show_col_types = FALSE,
col_types = "cccccccccdd"
) %>%
set_names(str_to_lower(names(.))) %>%
rename(c_a = `c/a`) %>%
filter(!(division %in% c("PTH", "RIT"))) %>%
transmute(
id = str_c(c_a, unit, scp, sep = "_"),
datetime = mdy_hms(str_c(date, time, sep = " ")),
station,
linename,
entries
) %>%
arrange(id, datetime) %>%
write_csv(path("data", "2022", str_c(latest_date_fmt, ".csv")))
## read data ------------------------------------------------------
df_ts <- read_csv(path("data", "turnstiles.csv"))
df_old_weekly <- read_csv(path("output", "2022_station_counts.csv"))
df_ts_new <- distinct(df_latest, id, station, linename) %>%
anti_join(df_ts, by = "id") %>%
{
if (nrow(.) > 0) {
# TODO: Add email component here
df_stations <- read_csv(path("data", "station_conversion.csv"))
left_join(
.,
df_stations,
by = c("station", "linename")
) %>%
transmute(id, station = coalesce(station_new, station),
linename = coalesce(linename_new, linename),
lat = Latitude, lon = Longitude) %>%
bind_rows(df_ts) %>%
write_csv(path("data", "turnstiles.csv"))
} else {
.
}
# daily turnstile counts ---------------------------------------------------
# TODO: Look into whether certain turnstiles swap their direction over time
#   - Should we be recalculating the direction each week?
#   - With what time window? (Ugh)
df_daily <- bind_rows(
select(df_ts, id, datetime, entries),
select(df_latest, id, datetime, entries)
) %>%
arrange(id, datetime) %>%
group_by(id) %>%
mutate(d_entries = entries - lag(entries)) %>%
ungroup() %>%
left_join(select(df_ts, id, sign), by = "id") %>%
filter(sign * d_entries < 0) %>%
arrange(id, datetime) %>%
group_by(id) %>%
mutate(d_entries = (entries - lag(entries)) * sign,
d_time    = (datetime %--% lag(datetime)) %/% hours()) %>%
ungroup() %>%
filter(d_entries < 10000, d_entries >= 0, d_time >= -12)
# weekly station counts ---------------------------------------------------
tictoc::tic()
df_new_weekly <- filter(
df_daily,
hour(datetime) %in% c(8:11, 18:21) |
wday(datetime) %in% c(1,7)
) %>%
mutate(
weekdate = floor_date(datetime, unit = "week", week_start = 1),
time = map_chr(
datetime,
~ case_when(
wday(.) %in% c(1,7) ~ "weekend",
hour(.) <= 11 ~ "weekday_am",
hour(.) >  11 ~ "weekday_pm"
)
) %>%
left_join(df_ts, by = "id") %>%
group_by(linename, station, weekdate, time) %>%
summarise(entries = sum(d_entries),
.groups = "drop") %>%
pivot_wider(
names_from = time,
values_from = entries
) %>%
full_join(
df_old_weekly,
by = c("linename", "station", "weekdate"),
suffix = c(".new", ".old")
) %>%
transmute(
linename,
station,
weekdate,
weekend = coalesce(weekend.new, weekend.old),
weekday_am = coalesce(weekday_am.new, weekday_am.old),
weekday_pm = coalesce(weekday_pm.new, weekday_pm.old)
) %>%
write_csv(path("output", str_c("test", "2022_station_counts.csv")), na = "")
tictoc::toc()
df_new_weekly
df_latest
View(df_new_weekly)
tictoc::tic()
df_new_weekly <- filter(
df_daily,
hour(datetime) %in% c(8:11, 18:21) |
wday(datetime) %in% c(1,7)
) %>%
mutate(
weekdate = floor_date(datetime, unit = "week", week_start = 1),
time = map_chr(
datetime,
~ case_when(
wday(.) %in% c(1,7) ~ "weekend",
hour(.) <= 11 ~ "weekday_am",
hour(.) >  11 ~ "weekday_pm"
)
) %>%
left_join(df_ts, by = "id") %>%
group_by(linename, station, weekdate, time) %>%
summarise(entries = sum(d_entries),
.groups = "drop") %>%
pivot_wider(
names_from = time,
values_from = entries
)
tictoc::toc()
df_new_weekly
bind_rows(
select(df_ts, id, datetime, entries),
select(df_latest, id, datetime, entries)
)
df_ts
bind_rows(
select(df_ts, id, datetime, entries),
select(df_latest, id, datetime, entries)
) %>%
arrange(id, datetime) %>%
group_by(id) %>%
mutate(d_entries = entries - lag(entries)) %>%
ungroup()
bind_rows(
select(df_ts, id, datetime, entries),
select(df_latest, id, datetime, entries)
) %>%
arrange(id, datetime) %>%
group_by(id) %>%
mutate(d_entries = entries - lag(entries)) %>%
ungroup() %>%
left_join(select(df_ts, id, sign), by = "id") %>%
filter(sign * d_entries < 0) %>%
arrange(id, datetime) %>%
group_by(id) %>%
mutate(d_entries = (entries - lag(entries)) * sign,
d_time    = (datetime %--% lag(datetime)) %/% hours()) %>%
ungroup()
# TODO: Look into whether certain turnstiles swap their direction over time
#   - Should we be recalculating the direction each week?
#   - With what time window? (Ugh)
df_daily <- bind_rows(
select(df_ts, id, datetime, entries),
select(df_latest, id, datetime, entries)
) %>%
arrange(id, datetime) %>%
group_by(id) %>%
mutate(d_entries = entries - lag(entries)) %>%
ungroup() %>%
left_join(select(df_ts, id, sign), by = "id") %>%
filter(sign * d_entries >= 0) %>%
arrange(id, datetime) %>%
group_by(id) %>%
mutate(d_entries = (entries - lag(entries)) * sign,
d_time    = (datetime %--% lag(datetime)) %/% hours()) %>%
ungroup() %>%
filter(d_entries < 10000, d_entries >= 0, d_time >= -12)
tictoc::tic()
df_new_weekly <- filter(
df_daily,
hour(datetime) %in% c(8:11, 18:21) |
wday(datetime) %in% c(1,7)
) %>%
mutate(
weekdate = floor_date(datetime, unit = "week", week_start = 1),
time = map_chr(
datetime,
~ case_when(
wday(.) %in% c(1,7) ~ "weekend",
hour(.) <= 11 ~ "weekday_am",
hour(.) >  11 ~ "weekday_pm"
)
) %>%
left_join(df_ts, by = "id") %>%
group_by(linename, station, weekdate, time) %>%
summarise(entries = sum(d_entries),
.groups = "drop") %>%
pivot_wider(
names_from = time,
values_from = entries
)
tictoc::toc()
tictoc::tic()
df_all_weekly <- full_join(
df_new_weekly,
df_old_weekly,
by = c("linename", "station", "weekdate"),
suffix = c(".new", ".old")
) %>%
transmute(
linename,
station,
weekdate,
weekend = coalesce(weekend.new, weekend.old),
weekday_am = coalesce(weekday_am.new, weekday_am.old),
weekday_pm = coalesce(weekday_pm.new, weekday_pm.old)
) %>%
write_csv(path("output", str_c("test", "2022_station_counts.csv")), na = "")
tictoc::toc()
df_new_weekly
df_new_weekly %>% arrange(linename, station, weekdate)
df_all_weekly %>% arrange(linename, station, weekdate)
df_all_weekly
df_ts_easy <- group_by(df_daily, id) %>%
filter(n() >= 5) %>%
ungroup() %>%
# identify most common nonzero sign direction
mutate(sign = sign(d_entries)) %>%
count(id, sign) %>%
filter(sign != 0) %>%
group_by(id) %>%
filter(n == max(n)) %>%
filter(n() == 1) %>%
ungroup()
df_ts_easy
df_ts_easy %>% full_join(df_ts, by = "id", suffix = c("_new", "_old")) %>% tabyl(sign_new, sign_old)
df_ts_easy %>% full_join(df_ts, by = "id", suffix = c("_new", "_old")) %>% janitor::tabyl(sign_new, sign_old)
install.packages("janitor")
df_ts_easy %>% full_join(df_ts, by = "id", suffix = c("_new", "_old")) %>% janitor::tabyl(sign_new, sign_old)
df_ts_easy %>% full_join(df_ts, by = "id", suffix = c("_new", "_old")) %>% filter(sign_new != sign_old)
df_ts_easy %>% full_join(df_ts, by = "id", suffix = c("_new", "_old")) %>% filter(sign_new != sign_old) %>% {filter(df_old_weekly, id %in% .$id)} %>% View
df_ts_easy %>% full_join(df_ts, by = "id", suffix = c("_new", "_old")) %>% filter(sign_new != sign_old) %>% pull(id) %>% {filter(df_old_weekly, id %in% .)} %>% View
df_ts_easy %>% full_join(df_ts, by = "id", suffix = c("_new", "_old")) %>% filter(sign_new != sign_old) %>% pull(id) %>% {filter(df_old_weekly, id %in% .)}
df_ts_easy %>% full_join(df_ts, by = "id", suffix = c("_new", "_old")) %>% filter(sign_new != sign_old) %>% pull(id)
df_ts_easy %>% full_join(df_ts, by = "id", suffix = c("_new", "_old")) %>% filter(sign_new != sign_old) %>% pull(id) -> test
View(df_old_weekly %>% filter(id %in% test))
df_old_weekly
df <- map_dfr(
dir_ls(path("data", "2022")),
~ vroom(., show_col_types = FALSE,
col_types = "cccccccccdd")
)
library(tidyverse)
library(lubridate)
library(fs)
library(scales)
library(vroom)
library(janitor)
df <- map_dfr(
dir_ls(path("data", "2022")),
~ vroom(., show_col_types = FALSE,
col_types = "cccccccccdd")
)
df
df <- map_dfr(
dir_ls(path("data", "2022")),
~ vroom(., show_col_types = FALSE,
col_types = "cccccccccdd"),
.id = "path"
)
df
df <- map_dfr(
dir_ls(path("data", "2022")),
~ vroom(., show_col_types = FALSE),
.id = "path"
)
df
df_daily <- arrange(df, id, datetime) %>%
group_by(id) %>%
mutate(d_entries = entries - lag(entries)) %>%
ungroup()
df_ts_dir <- group_by(df_daily, id, path) %>%
filter(n() >= 5) %>%
ungroup() %>%
# identify most common nonzero sign direction
mutate(sign = sign(d_entries)) %>%
count(id, path, sign) %>%
pivot_wider(names_from = sign, values_from = n)
df_ts_dir
df_ts_dir %>% View()
df_ts_dir <- group_by(df_daily, id, path) %>%
filter(n() >= 5) %>%
ungroup() %>%
# identify most common nonzero sign direction
mutate(sign = sign(d_entries)) %>%
count(id, path, sign) %>%
group_by(id, path) %>%
filter(n == max(n))
View(df_ts_dir)
df_ts_dir %>% count(id, sign)
df_ts_dir %>% ungroup() %>% count(id, sign)
df_ts_dir %>% ungroup() %>% count(id, sign) %>% View
df_ts_dir %>% ungroup() %>% count(id, sign) %>% group_by(id) %>% filter(n() >= 2)
df_ts_dir %>% ungroup() %>% count(id, sign) %>% group_by(id) %>% filter(n() >= 2) %>% View
prob_turnstiles <- c(
"B019_R149_00-00-01",
"H007A_R248_02-03-00",
"N329_R201_00-03-03",
"R232A_R176_03-06-00",
"R249_R179_01-00-05",
"R401_R445_00-00-00",
"R412_R146_00-00-00"
)
df_daily %>% filter(id == prob_turnstiles[[1]])
df_daily %>% filter(id == prob_turnstiles[[1]]) %>% View
df_daily %>% filter(id == prob_turnstiles[[2]]) %>% View
df_ts
df_ts <- read_csv(path("data", "turnstiles.csv"))
df_ts
# TODO: Look into whether certain turnstiles swap their direction over time
#   - Should we be recalculating the direction each week?
#   - With what time window? (Ugh)
df_daily <- bind_rows(
select(df_ts, id, datetime, entries),
select(df_latest, id, datetime, entries)
) %>%
arrange(id, datetime) %>%
group_by(id) %>%
mutate(d_entries = entries - lag(entries)) %>%
ungroup()
mta_base_url <- "http://web.mta.info/developers/data/nyct/turnstile/turnstile_"
latest_date <- floor_date(Sys.Date(), "week", 6)
latest_date_fmt <- label_date(format = "%y%m%d")(latest_date)
latest_date_url <- str_c(mta_base_url, latest_date_fmt, ".txt")
df_latest <- read_csv(path("data", "2022", str_c(latest_date_fmt, ".csv")))
df_old_ts <- read_csv(path("data", "turnstiles.csv"))
df_old_weekly <- read_csv(path("output", "2022_station_counts.csv"))
# TODO: Look into whether certain turnstiles swap their direction over time
#   - Should we be recalculating the direction each week?
#   - With what time window? (Ugh)
df_daily <- bind_rows(
select(df_ts, id, datetime, entries),
select(df_latest, id, datetime, entries)
) %>%
arrange(id, datetime) %>%
group_by(id) %>%
mutate(d_entries = entries - lag(entries)) %>%
ungroup()
df_daily
df_ts_dir <- group_by(df_daily, id, path) %>%
filter(n() >= 5) %>%
ungroup() %>%
# identify most common nonzero sign direction
mutate(sign = sign(d_entries)) %>%
count(id, path, sign) %>%
filter(n != 0) %>%
group_by(id, path) %>%
filter(n == max(n))
df_ts_dir <- group_by(df_daily_raw, id) %>%
filter(n() >= 5) %>%
ungroup() %>%
# identify most common nonzero sign direction
mutate(sign = sign(d_entries)) %>%
count(id, sign) %>%
filter(n != 0) %>%
group_by(id) %>%
filter(n == max(n))
# TODO: Look into whether certain turnstiles swap their direction over time
#   - Should we be recalculating the direction each week?
#   - With what time window? (Ugh)
df_daily_raw <- bind_rows(
select(df_ts, id, datetime, entries),
select(df_latest, id, datetime, entries)
) %>%
arrange(id, datetime) %>%
group_by(id) %>%
mutate(d_entries = entries - lag(entries)) %>%
ungroup()
df_ts_dir <- group_by(df_daily_raw, id) %>%
filter(n() >= 5) %>%
ungroup() %>%
# identify most common nonzero sign direction
mutate(sign = sign(d_entries)) %>%
count(id, sign) %>%
filter(n != 0) %>%
group_by(id) %>%
filter(n == max(n))
df_ts_dir
df_ts_dir %>% filter(sign != 1)
df_ts_dir <- group_by(df_daily_raw, id) %>%
filter(n() >= 5) %>%
ungroup() %>%
# identify most common nonzero sign direction
mutate(sign = sign(d_entries)) %>%
count(id, sign) %>%
filter(sign != 0) %>%
group_by(id) %>%
filter(n == max(n))
df_ts_dir
df_ts_dir %>% filter(sign != 1)
df_ts_dir <- group_by(df_daily_raw, id) %>%
filter(n() >= 5) %>%
ungroup() %>%
# identify most common nonzero sign direction
mutate(sign = sign(d_entries)) %>%
filter(sign != 0) %>%
count(id, sign) %>%
group_by(id) %>%
filter(n == max(n))
df_ts_dir
left_join(
df_daily_raw,
df_ts_dir,
by = "id"
)
left_join(
df_daily_raw,
df_ts_dir,
by = "id"
) %>%
filter(sign * d_entries >= 0)
df_daily <- left_join(
df_daily_raw,
df_ts_dir,
by = "id"
)
df_daily %>% filter(sign * d_entries < 0)
df_daily %>% filter(sign * d_entries < 0) %>% View
df_latest %>% filter(id == "R249_R179_01-05-01") %>% View
df_daily %>% filter(is.na(sign))
df_daily %>% filter(is.na(sign)) %>% View
df_ts
df_daily_raw %>% group_by(id) %>% filter(datetime == max(datetime))
nrow(df_old_ts)
df_old_ts <- read_csv(path("data", "turnstiles.csv"))
df_old_weekly <- read_csv(path("output", "2022_station_counts.csv"))
# TODO: Look into whether certain turnstiles swap their direction over time
#   - Should we be recalculating the direction each week?
#   - With what time window? (Ugh)
df_daily_raw <- bind_rows(
select(df_old_ts, id, datetime, entries),
select(df_latest, id, datetime, entries)
) %>%
arrange(id, datetime) %>%
group_by(id) %>%
mutate(d_entries = entries - lag(entries)) %>%
ungroup()
df_daily_raw
df_daily_raw %>% group_by(id) %>% filter(datetime == max(datetime))
df_old_ts %>% group_by(id)
bind_rows(
select(df_old_ts, id, datetime, entries),
select(df_latest, id, datetime, entries)
) %>%
arrange(id, datetime) %>%
group_by(id)
bind_rows(
select(df_old_ts, id, datetime, entries),
select(df_latest, id, datetime, entries)
) %>%
arrange(id, datetime) %>%
group_by(id) %>%
mutate(d_entries = entries - lag(entries))
df_old_ts %>% filter(is.na(datetime))
df_stations <- read_csv(path("data", "stations_conversion.csv"))
dir_ls("data")
df_stations <- read_csv(path("data", "station_conversion.csv"))
group_by(df_daily_raw, id) %>%
filter(datetime == max(datetime)) %>%
left_join(df_stations, by = c("id"))
df_daily_raw
df_ts <- group_by(df_daily_raw, id) %>%
filter(datetime == max(datetime)) %>%
left_join(
select(df_old_ts, id, station, linename, lon, lat),
by = "id"
)
df_ts %>% filter(is.na(lon))
df_ts <- group_by(df_daily_raw, id) %>%
filter(datetime == max(datetime)) %>%
left_join(
select(df_old_ts, id, station, linename, lon, lat),
by = "id"
) %>%
## TODO: This might be the spot where to send turnstiles w/o longitude/latitude
left_join(
df_stations, by = c("station", "linename"), suffix = c("_old", "_new")
)
df_ts %>% filter(is.na(lon))
df_ts %>% filter(is.na(lon)) %>% View
df_stations
df_stations %>% filter(str_detect(station, "PARK PLACE"))
df_stations %>% filter(str_detect(linename, "ACE23"))
df_stations %>% filter(str_detect(station, "JAY ST"))
